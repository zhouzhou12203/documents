# Thread Configuration - 线程配置
# 生成时采用的最大线程数，5-10即可。会带来成倍的API调用费用，不要设置过高！
MAX_THREAD_NUM=5


# Server Configuration - Docker服务配置
# 前端服务端口
FRONTEND_PORT=80
# 后端服务端口
BACKEND_PORT=7869
# 后端服务监听地址
BACKEND_HOST=0.0.0.0
# Gunicorn工作进程数
WORKERS=4
# 每个工作进程的线程数
THREADS=2
# 请求超时时间（秒）
TIMEOUT=120

# 是否启用在线演示
# 不用设置，默认不启用
ENABLE_ONLINE_DEMO=False

# Backend Configuration - 后端配置
# 导入小说时，最大的处理长度，超出该长度的文本不会进行处理，可以考虑增加
MAX_NOVEL_SUMMARY_LENGTH=20000


# MongoDB Configuration - MongoDB数据库配置
# 安装了MongoDB才需要配置，否则不用改动
# 是否启用MongoDB，启用后下面配置才有效
ENABLE_MONGODB=false
# MongoDB连接地址，使用host.docker.internal访问宿主机MongoDB
MONGODB_URI=mongodb://host.docker.internal:27017/
# MongoDB数据库名称
MONGODB_DB_NAME=llm_api
# 是否启用API缓存
ENABLE_MONGODB_CACHE=true
# 缓存命中后重放速度倍率
CACHE_REPLAY_SPEED=2
# 缓存命中后最大延迟时间（秒）
CACHE_REPLAY_MAX_DELAY=5


# API Cost Limits - API费用限制设置，需要依赖于MongoDB
# 每小时费用上限（人民币）
API_HOURLY_LIMIT_RMB=100
# 每天费用上限（人民币）
API_DAILY_LIMIT_RMB=500
# 美元兑人民币汇率
API_USD_TO_RMB_RATE=7


# Wenxin API Settings - 文心API配置
# 文心API的AK，获取地址：https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application
WENXIN_AK=
WENXIN_SK=
WENXIN_AVAILABLE_MODELS=ERNIE-Novel-8K,ERNIE-4.0-8K,ERNIE-3.5-8K

# Doubao API Settings - 豆包API配置
# DOUBAO_ENDPOINT_IDS和DOUBAO_AVAILABLE_MODELS一一对应，有几个模型就对应几个endpoint_id，这是豆包强制要求的
# 你可以自行设置DOUBAO_AVAILABLE_MODELS，不一定非要采用下面的
DOUBAO_API_KEY=
DOUBAO_ENDPOINT_IDS=
DOUBAO_AVAILABLE_MODELS=doubao-pro-32k,doubao-lite-32k

# GPT API Settings - GPT API配置
GPT_BASE_URL=https://12203gemini.deno.dev
GPT_API_KEY=https://12203gemini.deno.dev
GPT_AVAILABLE_MODELS=Gemini 2.0 Flash,gemini-2.5-pro-exp-03-25

# GPT API Settings - GPT API配置
GEMINI_BASE_URL=Gemini 2.0 Flash,gemini-2.5-pro-exp-03-25
GEMINI_API_KEY=https://gemini.xxxv.me
GEMINI_AVAILABLE_MODELS=Gemini 2.0 Flash,gemini-2.5-pro-exp-03-25

# Local Model Settings - 本地模型配置
# 本地模型配置需要把下面的localhost替换为host.docker.internal，把8000替换为你的本地大模型服务端口
# 把local-key替换为你的本地大模型服务API_KEY，把local-model-1替换为你的本地大模型服务模型名
# 并且docker启动方式有变化，详细参考readme
LOCAL_BASE_URL=http://localhost:8000/v1
LOCAL_API_KEY=local-key
LOCAL_AVAILABLE_MODELS=local-model-1

# Zhipuai API Settings - 智谱AI配置
ZHIPUAI_API_KEY=
ZHIPUAI_AVAILABLE_MODELS=glm-4-air,glm-4-flashx

# Default Model Settings - 默认模型设置
# 例如：wenxin/ERNIE-Novel-8K, doubao/doubao-pro-32k, gpt/gpt-4o-mini, local/local-model-1
DEFAULT_MAIN_MODEL=zhipuai/glm-4-air
DEFAULT_SUB_MODEL=zhipuai/glm-4-flashx
